{"metadata": {
    "kernelspec": {
        "name": "spark",
        "display_name": "Spark 1.1.0 (Scala 2.10.4)"
    }
}, "cells": [
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "sc",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 3,
                "data": {
                    "text/plain": "res5: org.apache.spark.SparkContext = org.apache.spark.SparkContext@4de91056"
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 3
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "val in = scala.io.Source.fromURL(\"http://172.31.2.11:31410/db/charmander/series?u=root&p=root&q=\"+java.net.URLEncoder.encode(\" select memory_usage from stats limit 200\"), \"utf-8\")",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 4,
                "data": {
                    "text/plain": "warning: there were 1 deprecation warning(s); re-run with -deprecation for details\nin: scala.io.BufferedSource = non-empty iterator"
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 4
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "var data = \"\"\nfor (line <- in.getLines)\ndata = line",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 5,
                "data": {
                    "text/plain": "data: String = [{\"name\":\"stats\",\"columns\":[\"time\",\"sequence_number\",\"memory_usage\"],\"points\":[[1419995633000,111600001,84946944],[1419995633000,111000001,84946944],[1419995633000,110400001,84946944],[1419995632000,111590001,84946944],[1419995632000,110990001,84946944],[1419995632000,110390001,84946944],[1419995631000,111580001,84946944],[1419995631000,110980001,84946944],[1419995631000,110380001,84946944],[1419995630000,111570001,84946944],[1419995630000,110970001,84946944],[1419995630000,110370001,84946944],[1419995629000,111560001,84946944],[1419995629000,110960001,84946944],[1419995629000,110360001,84946944],[1419995628000,111550001,84946944],[1419995628000,110950001,84946944],[1419995628000,110350001,84946944],[1419995627000,111540001,84946944],[1419995627000,110940001,84946944],[14..."
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 5
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "import org.json4s.jackson.JsonMethods\n",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 6,
                "data": {
                    "text/plain": "import org.json4s.jackson.JsonMethods"
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 6
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "val json = JsonMethods.parse(data)",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 7,
                "data": {
                    "text/plain": "json: org.json4s.JValue = JArray(List(JObject(List((name,JString(stats)), (columns,JArray(List(JString(time), JString(sequence_number), JString(memory_usage)))), (points,JArray(List(JArray(List(JInt(1419995633000), JInt(111600001), JInt(84946944))), JArray(List(JInt(1419995633000), JInt(111000001), JInt(84946944))), JArray(List(JInt(1419995633000), JInt(110400001), JInt(84946944))), JArray(List(JInt(1419995632000), JInt(111590001), JInt(84946944))), JArray(List(JInt(1419995632000), JInt(110990001), JInt(84946944))), JArray(List(JInt(1419995632000), JInt(110390001), JInt(84946944))), JArray(List(JInt(1419995631000), JInt(111580001), JInt(84946944))), JArray(List(JInt(1419995631000), JInt(110980001), JInt(84946944))), JArray(List(JInt(1419995631000), JInt(110380001), JInt(84946944))), JAr..."
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 7
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "val points = json \\\\ \"points\"",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 8,
                "data": {
                    "text/plain": "points: org.json4s.JValue = JArray(List(JArray(List(JInt(1419995633000), JInt(111600001), JInt(84946944))), JArray(List(JInt(1419995633000), JInt(111000001), JInt(84946944))), JArray(List(JInt(1419995633000), JInt(110400001), JInt(84946944))), JArray(List(JInt(1419995632000), JInt(111590001), JInt(84946944))), JArray(List(JInt(1419995632000), JInt(110990001), JInt(84946944))), JArray(List(JInt(1419995632000), JInt(110390001), JInt(84946944))), JArray(List(JInt(1419995631000), JInt(111580001), JInt(84946944))), JArray(List(JInt(1419995631000), JInt(110980001), JInt(84946944))), JArray(List(JInt(1419995631000), JInt(110380001), JInt(84946944))), JArray(List(JInt(1419995630000), JInt(111570001), JInt(84946944))), JArray(List(JInt(1419995630000), JInt(110970001), JInt(84946944))), JArray(Li..."
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 8
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "val mypoints = points.values",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 9,
                "data": {
                    "text/plain": "mypoints: points.Values = List(List(1419995633000, 111600001, 84946944), List(1419995633000, 111000001, 84946944), List(1419995633000, 110400001, 84946944), List(1419995632000, 111590001, 84946944), List(1419995632000, 110990001, 84946944), List(1419995632000, 110390001, 84946944), List(1419995631000, 111580001, 84946944), List(1419995631000, 110980001, 84946944), List(1419995631000, 110380001, 84946944), List(1419995630000, 111570001, 84946944), List(1419995630000, 110970001, 84946944), List(1419995630000, 110370001, 84946944), List(1419995629000, 111560001, 84946944), List(1419995629000, 110960001, 84946944), List(1419995629000, 110360001, 84946944), List(1419995628000, 111550001, 84946944), List(1419995628000, 110950001, 84946944), List(1419995628000, 110350001, 84946944), List(14199..."
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 9
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "val rdd = sc.parallelize(mypoints.asInstanceOf[List[List[BigDecimal]]])",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 10,
                "data": {
                    "text/plain": "rdd: org.apache.spark.rdd.RDD[List[BigDecimal]] = ParallelCollectionRDD[1] at parallelize at <console>:55"
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 10
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "case class MemoryUsage(timestamp: BigDecimal, memory: BigDecimal)",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 11,
                "data": {
                    "text/plain": "defined class MemoryUsage"
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 11
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "val memoryusage = rdd.map(p => MemoryUsage(BigDecimal(p(0).asInstanceOf[BigInt]), BigDecimal(p(2).asInstanceOf[BigInt])))",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 12,
                "data": {
                    "text/plain": "memoryusage: org.apache.spark.rdd.RDD[MemoryUsage] = MappedRDD[2] at map at <console>:65"
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 12
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\nimport sqlContext._",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 13,
                "data": {
                    "text/plain": "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@31b84ec9\nimport sqlContext._"
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 13
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "memoryusage.registerTempTable(\"memoryusage\")",
        "outputs": [],
        "cell_type": "code",
        "execution_count": 14
    },
    {
        "metadata": {
            "collapsed": false,
            "trusted": true
        },
        "source": "val newestMaxRaw = sqlContext.sql(\"select max(memory) from memoryusage\").first()",
        "outputs": [
            {
                "metadata": {},
                "output_type": "execute_result",
                "execution_count": 15,
                "data": {
                    "text/plain": "newestMaxRaw: org.apache.spark.sql.Row = [84946944]"
                }
            }
        ],
        "cell_type": "code",
        "execution_count": 15
    },
    {
        "metadata": {
            "collapsed": true,
            "trusted": true
        },
        "source": "",
        "outputs": [],
        "cell_type": "code",
        "execution_count": 16
    }
], "nbformat": 4, "nbformat_minor": 0}